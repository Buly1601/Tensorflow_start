{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abstract_ordening.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract ordening neural netowrk testing\n",
        "This neural networks's job is to order and differentiate an abstract, recognizing objective, methods, results, conclusions from a single abstract.\n",
        "Using CNNs, vectorizing and embedding of the strings\n"
      ],
      "metadata": {
        "id": "6HMDUipUJbGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions\n",
        "- convert txt to list of dictionaries\n",
        "- calculate performance of model\n",
        "- fitting model function\n",
        "- splitting a sentence into chars\n",
        "\n"
      ],
      "metadata": {
        "id": "96N4jO-TLpUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def from_text_to_dict(text_dir):\n",
        "  \"\"\"\n",
        "  Imports from the directory, separates and turns into\n",
        "  list of dictionaries as seen here\n",
        "  -> list of dicts = [{\"line num\": 0,\n",
        "    \"text\": \"fdksldkfm\",\n",
        "    \"target\": \"BACKGROUND\",\n",
        "    \"lines_per_paper\": 11}\n",
        "    ...]\n",
        "  \"\"\"\n",
        "  with open(text_dir) as t:\n",
        "    # get list of each line\n",
        "    lines = t.readlines()\n",
        "    \n",
        "    # get each abstract in a list, convert to a list of lists\n",
        "    counter = 0\n",
        "    abstracts = []\n",
        "    abstract = []\n",
        "    for line in lines:\n",
        "      # line with len == 1 is abstract separator\n",
        "      if len(line) == 1:\n",
        "        abstracts.append(abstract)\n",
        "        abstract = []\n",
        "      else:\n",
        "        # do not append abstract number\n",
        "        if line[0] != \"#\":\n",
        "          abstract.append(line)\n",
        "    \n",
        "    # dictionary to return\n",
        "    list_of_dicts = []\n",
        "\n",
        "    for a in abstracts:\n",
        "      total_lines = len(a)\n",
        "      # get all the sentences\n",
        "      for i, sentence in enumerate(a):\n",
        "        # separate label from sentence\n",
        "        separated = \"\".join(sentence).split(\"\\t\")\n",
        "        # get info in dictionary\n",
        "        helper = {\n",
        "            \"line_num\": i,\n",
        "            \"sentence\": separated[1],\n",
        "            \"target\": separated[0],\n",
        "            \"lines_per_abstract\": total_lines - 1\n",
        "        }\n",
        "        # append to list\n",
        "        list_of_dicts.append(helper)\n",
        "\n",
        "    return list_of_dicts\n"
      ],
      "metadata": {
        "id": "RzMJPk9qLotn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_result(prediction, labels):\n",
        "  \"\"\"\n",
        "  Calculates f1-score, accuracy, precision and recall.\n",
        "  Returns dictionary with said information.\n",
        "  \"\"\"\n",
        "  from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "  \n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(prediction, labels) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(prediction, labels, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results\n",
        "\n",
        "  return result_dict"
      ],
      "metadata": {
        "id": "-XPsaIM0PJLx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_model(model):\n",
        "  \"\"\"\n",
        "  Fits the model and returns the history of the \n",
        "  fitting.\n",
        "  \"\"\"\n",
        "\n",
        "  history = model.fit(train_dataset, epochs=5, steps_per_epoch=int(0.2*len(train_dataset)),\n",
        "                     validation_data=validation_dataset, validation_steps=int(0.2*len(validation_dataset)))\n",
        "  \n",
        "  return history"
      ],
      "metadata": {
        "id": "5KNUatDU2453"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_characters(sentence):\n",
        "  \"\"\" \n",
        "  Returns the a string of space-separated characters \n",
        "  of the original sentnce.\n",
        "  \"\"\"\n",
        "\n",
        "  return \" \".join(list(sentence))"
      ],
      "metadata": {
        "id": "LeFNZzjs9OG-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "ni-8x0oCKd1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM8lq3BvJB-U",
        "outputId": "826ab3a8-cec4-4990-acd0-ed63e5cb9f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "Checking out files: 100% (13/13), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ],
      "source": [
        "# get the data (Google Colab way)\n",
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import data from folder to instance\n",
        "import pandas as pd\n",
        "train_data = from_text_to_dict(\"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt\")\n",
        "test_data = from_text_to_dict(\"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt\")\n",
        "validation_data = from_text_to_dict(\"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt\")\n",
        "\n",
        "# convert to dataframes\n",
        "train_data_dataframe = pd.DataFrame(train_data)\n",
        "test_data_dataframe = pd.DataFrame(test_data)\n",
        "validation_data_dataframe = pd.DataFrame(validation_data)\n",
        "\n",
        "# observe result\n",
        "# train_data_dataframe.head(12)"
      ],
      "metadata": {
        "id": "HX9IYj40LHPe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3Qn_PWFW6Du",
        "outputId": "d2e044d0-1252-4c19-873b-deeba74e434c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'line_num': 0,\n",
              " 'lines_per_abstract': 11,\n",
              " 'sentence': 'To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'target': 'OBJECTIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get lists of all sentences \n",
        "train_sentences = train_data_dataframe[\"sentence\"].tolist()\n",
        "test_sentences = test_data_dataframe[\"sentence\"].tolist()\n",
        "validation_sentences = validation_data_dataframe[\"sentence\"].tolist()"
      ],
      "metadata": {
        "id": "iZSDi0cpZH58"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode labels \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_ohe = one_hot_encoder.fit_transform(train_data_dataframe[\"target\"].to_numpy().reshape(-1, 1)) # first one is fitted to data\n",
        "test_labels_ohe = one_hot_encoder.transform(test_data_dataframe[\"target\"].to_numpy().reshape(-1, 1)) \n",
        "validation_labels_ohe = one_hot_encoder.transform(validation_data_dataframe[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# observe results\n",
        "# train_labels_ohe"
      ],
      "metadata": {
        "id": "szprgfsGZzoR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label encode labels, encode to integers [0, ... , number_of_classes]\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_data_dataframe[\"target\"].to_numpy()) # first one is fitted to data\n",
        "test_labels_encoded = label_encoder.fit_transform(test_data_dataframe[\"target\"].to_numpy())\n",
        "validation_labels_encoded = label_encoder.fit_transform(validation_data_dataframe[\"target\"].to_numpy())\n",
        "\n",
        "# observe results\n",
        "# train_labels_encoded"
      ],
      "metadata": {
        "id": "Flmf35b-fxyH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get name and ammount of labels\n",
        "num_labels = len(label_encoder.classes_)\n",
        "labels = label_encoder.classes_"
      ],
      "metadata": {
        "id": "hpZsIHN2gydQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXXed3GiTBSe",
        "outputId": "815ed605-a041-4bcc-8ee0-c31f0bbc8484"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define embedding information\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# find average of sentence length in training sentences\n",
        "sentence_lengths = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sentence_length = np.round(np.average(sentence_lengths))\n",
        "# avg_sentence_length \n",
        "# average is 26 -- \n",
        "\n",
        "# observe sentences lengths' distribution\n",
        "plt.hist(sentence_lengths, bins=20);\n",
        "# ~95% are from 0 - ~60\n",
        "# assert observation\n",
        "most_s_lens = int(np.percentile(sentence_lengths, 95))\n",
        "print(f\"assertion -> {most_s_lens}\")\n",
        "# 95% are 55"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "TgXrRuxzhGh4",
        "outputId": "6b1202dc-56fa-4855-91ff-b7b64e6d62b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assertion -> 55\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create tensorflow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_ohe))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_ohe))\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_sentences, validation_labels_ohe))\n",
        "\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "validation_dataset = validation_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "nucU8luRaOye"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split sequence-level data split into character-level data splits\n",
        "train_chars = [split_characters(sentence) for sentence in train_sentences]\n",
        "validation_chars = [split_characters(sentence) for sentence in validation_sentences]\n",
        "test_chars = [split_characters(sentence) for sentence in test_sentences]"
      ],
      "metadata": {
        "id": "kJByenQU9B-y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define char embedding information\n",
        "# find average length of sentences\n",
        "chars_lens = [len(split_characters(sentence)) for sentence in train_sentences]\n",
        "avg_chars_sentence = np.round(np.average(chars_lens))\n",
        "# avg_chars_sentence\n",
        "# average is 300 chars/sentence\n",
        "\n",
        "# observe chars distribution in training sentences\n",
        "plt.hist(chars_lens, bins=20);\n",
        "# 95% are from 0 - ~510\n",
        "\n",
        "# assert observation\n",
        "most_c_lens = np.percentile(chars_lens, 95)\n",
        "print(f\"assertion -> {most_c_lens}\")\n",
        "# 95% are 581"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Zb4M_gOw97C1",
        "outputId": "0847bc76-4ff4-4dd4-dc41-971a0b099da0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assertion -> 581.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all keyboard chars, ammount\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alpha_len = len(alphabet)"
      ],
      "metadata": {
        "id": "ukQiRmdUAhM-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create hybrid datasets\n",
        "train_data_char_sentence = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # data has to be in the SAME order as constructed\n",
        "train_labels_char_sentence = tf.data.Dataset.from_tensor_slices((train_labels_ohe))\n",
        "train_dataset_hybrid = tf.data.Dataset.zip((train_data_char_sentence, train_labels_char_sentence)) # combine into single training dataset\n",
        "\n",
        "validation_data_char_sentence = tf.data.Dataset.from_tensor_slices((validation_sentences, validation_chars)) # data has to be in the SAME order as constructed\n",
        "validation_labels_char_sentence = tf.data.Dataset.from_tensor_slices((validation_labels_ohe))\n",
        "validation_dataset_hybrid = tf.data.Dataset.zip((validation_data_char_sentence, validation_labels_char_sentence)) # combine into single training dataset\n",
        "\n",
        "train_data_char_sentence = train_data_char_sentence.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "train_labels_char_sentence = train_labels_char_sentence.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "train_dataset_hybrid = train_dataset_hybrid.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "validation_data_char_sentence = validation_data_char_sentence.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "validation_labels_char_sentence = validation_labels_char_sentence.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "validation_dataset_hybrid = validation_dataset_hybrid.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "-Y06wdAPr3go"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index one-hot-encoding \n",
        "# get the best number of lines in abstracts\n",
        "train_data_dataframe.line_num.plot.hist(bins=20)\n",
        "# 18 gets around 90%\n",
        "\n",
        "train_index_ohe = tf.one_hot(train_data_dataframe[\"line_num\"].to_numpy(), depth=18)\n",
        "validation_index_ohe = tf.one_hot(validation_data_dataframe[\"line_num\"].to_numpy(), depth=18)\n",
        "test_index_ohe = tf.one_hot(test_data_dataframe[\"line_num\"].to_numpy(), depth=18)\n",
        "\n",
        "# use the same number for total lines in abstract\n",
        "train_total_ohe = tf.one_hot(train_data_dataframe[\"lines_per_abstract\"].to_numpy(), depth=18)\n",
        "validation_total_ohe = tf.one_hot(validation_data_dataframe[\"lines_per_abstract\"].to_numpy(), depth=18)\n",
        "test_total_ohe = tf.one_hot(test_data_dataframe[\"lines_per_abstract\"].to_numpy(), depth=18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nnR7PedoCVRc",
        "outputId": "a15b03fb-650b-4e82-bec2-636c94162b15"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create tri-hybrid datasets\n",
        "train_sentence_idx_tot = tf.data.Dataset.from_tensor_slices((train_index_ohe, train_total_ohe, train_sentences))\n",
        "train_sentence_idx_tot_labels = tf.data.Dataset.from_tensor_slices(train_labels_ohe)\n",
        "train_tribrid_dataset = tf.data.Dataset.zip((train_sentence_idx_tot, train_sentence_idx_tot_labels))\n",
        "train_tribrid_dataset = train_tribrid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_sentence_idx_tot_val = tf.data.Dataset.from_tensor_slices((validation_index_ohe, validation_total_ohe, validation_sentences))\n",
        "train_sentence_idx_tot_labels_val = tf.data.Dataset.from_tensor_slices(validation_labels_ohe)\n",
        "validation_tribrid_dataset = tf.data.Dataset.zip((train_sentence_idx_tot, train_sentence_idx_tot_labels))\n",
        "validation_tribrid_dataset = validation_tribrid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "iIDi5tZkCERs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Useful Keras Layers\n",
        "- Word vectorization layer\n",
        "- Embedding layer\n",
        "- Character vectorization layer"
      ],
      "metadata": {
        "id": "XktF0qZvj0mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorization layer \n",
        "# ammount of tokens (https://arxiv.org/pdf/1710.06071.pdf page 3)\n",
        "max_tokens = 68000\n",
        "# create vectorization layer\n",
        "text_vectorization_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=max_tokens, # vocabulary length of train data\n",
        "                                                                                        output_sequence_length=most_s_lens) # accomodate for 95%\n",
        "\n",
        "# adapt to dataset\n",
        "text_vectorization_layer.adapt(train_sentences)\n",
        "\n",
        "# test on random sentence and observe shape\n",
        "sample = \"this is a test made for this experiment\"\n",
        "print(text_vectorization_layer([sample]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xml1pWgiqou",
        "outputId": "2c9ad7a5-350b-49a0-d949-3b4c193dbc3c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  23   20    8  128 1050   11   23 2552    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]], shape=(1, 55), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding layer\n",
        "# get vocabulary\n",
        "data_vocabulary = text_vectorization_layer.get_vocabulary()\n",
        "token_embedding_layer = layers.Embedding(input_dim=len(data_vocabulary), output_dim=128,\n",
        "                                                       mask_zero=True, name=\"token_embedding_layer\")\n",
        "# observe result\n",
        "print(token_embedding_layer(text_vectorization_layer([sample])))\n",
        "# shape must be 1 sentence, 55 tokens, 128 embedding-per-token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCUxey6mlQe4",
        "outputId": "60a293e0-04db-43ab-8c95-ec93b5869f96"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0.04322379  0.01551266 -0.00571982 ...  0.00481644  0.04445176\n",
            "   -0.00235121]\n",
            "  [ 0.02555771  0.02199808 -0.04634216 ...  0.00566559  0.00549475\n",
            "    0.03073646]\n",
            "  [-0.01232402  0.00915813 -0.02863557 ...  0.02851471 -0.00616484\n",
            "   -0.03210302]\n",
            "  ...\n",
            "  [-0.01429086  0.03403969  0.01062155 ...  0.03385184 -0.04312538\n",
            "   -0.04870063]\n",
            "  [-0.01429086  0.03403969  0.01062155 ...  0.03385184 -0.04312538\n",
            "   -0.04870063]\n",
            "  [-0.01429086  0.03403969  0.01062155 ...  0.03385184 -0.04312538\n",
            "   -0.04870063]]], shape=(1, 55, 128), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# character vectorization layer\n",
        "max_char_tokens = alpha_len + 2 # add space and OOV\n",
        "character_vectorization_layer = tf.keras.layers.TextVectorization(max_tokens=max_char_tokens, # chars lens in alphabet\n",
        "                                                         output_sequence_length=int(most_c_lens), # accomodate for 95%\n",
        "                                                         standardize=\"lower_and_strip_punctuation\") \n",
        "\n",
        "# adapt to dataset\n",
        "character_vectorization_layer.adapt(train_chars)\n",
        "\n",
        "# test on random sentence and observe shape\n",
        "sample_c = \"A f t e r   @ m o n t h s\"\n",
        "print(character_vectorization_layer([sample_c]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P37JQkYOBJ69",
        "outputId": "b96d3cfe-3cdd-4edf-d85d-48c2282b2fdd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 5 17  3  2  8 15  7  6  3 13  9  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0]], shape=(1, 581), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# character embedding layer\n",
        "# get character vocabulary\n",
        "char_vocab = character_vectorization_layer.get_vocabulary()\n",
        "character_embedding_layer = tf.keras.layers.Embedding(input_dim=len(char_vocab),\n",
        "                                                      output_dim=20, # paper fig 1\n",
        "                                                      mask_zero=True)\n",
        "\n",
        "# observe result\n",
        "print(character_embedding_layer(character_vectorization_layer([sample_c])))\n",
        "# shape must be 1 sentence, 581 tokens, 20 embedding-per-token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gayQRURtDV6q",
        "outputId": "6f7be032-0021-40ab-d2e5-91031dc3fe1b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0.02178346 -0.031915    0.02053697 ... -0.00524558 -0.04439155\n",
            "    0.04902664]\n",
            "  [-0.00751108 -0.00986353 -0.02377131 ...  0.02044674 -0.04896079\n",
            "   -0.01680754]\n",
            "  [ 0.03930097 -0.01544137 -0.01673397 ... -0.00311076 -0.00621986\n",
            "   -0.00271805]\n",
            "  ...\n",
            "  [ 0.01493483  0.01522154  0.0468394  ...  0.01623854  0.01721411\n",
            "   -0.0323495 ]\n",
            "  [ 0.01493483  0.01522154  0.0468394  ...  0.01623854  0.01721411\n",
            "   -0.0323495 ]\n",
            "  [ 0.01493483  0.01522154  0.0468394  ...  0.01623854  0.01721411\n",
            "   -0.0323495 ]]], shape=(1, 581, 20), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dataframe.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "NdBjbaxD9rIJ",
        "outputId": "7a290daa-da60-4d57-97c4-5495d24b3838"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-165e169c-9f5d-4717-ad9c-6a0ac0fa7faf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>line_num</th>\n",
              "      <th>sentence</th>\n",
              "      <th>target</th>\n",
              "      <th>lines_per_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>To investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A total of @ patients with primary knee OA wer...</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Outcome measures included pain reduction and i...</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-165e169c-9f5d-4717-ad9c-6a0ac0fa7faf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-165e169c-9f5d-4717-ad9c-6a0ac0fa7faf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-165e169c-9f5d-4717-ad9c-6a0ac0fa7faf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   line_num  ... lines_per_abstract\n",
              "0         0  ...                 11\n",
              "1         1  ...                 11\n",
              "2         2  ...                 11\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models\n",
        "- model_0 -> tfidf model\n",
        "- model_1 -> recurrent neural network\n",
        "- model_2 -> LSTM model\n",
        "- model_3 -> bi-hybrid model (sentences and characters)\n",
        "- model_4 -> tri-hybrid model (sentences and line index)\n"
      ],
      "metadata": {
        "id": "zU5a03yfm_QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_0 \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# create model 0 as sklearn pipeline\n",
        "model_0 = Pipeline([\n",
        "  (\"tf_idf\", TfidfVectorizer()),\n",
        "  (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# fit the pipeline\n",
        "model_0.fit(X=train_sentences, y=train_labels_encoded)\n",
        "\n",
        "# evaluate pipeline\n",
        "model_0.score(X=validation_sentences, y=validation_labels_encoded)\n",
        "\n",
        "# predict with model\n",
        "pred_0 = model_0.predict(validation_sentences)\n",
        "\n",
        "# observe performance\n",
        "calculate_result(pred_0, validation_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KndFH6v0nF3k",
        "outputId": "7994c6d8-a676-42ee-e44c-de9b55e60c91"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.7447397336209445,\n",
              " 'precision': 0.7835634520695112,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create model 1 as rnn\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "# vectorizing and embedding layers\n",
        "o = text_vectorization_layer(inputs)\n",
        "o = token_embedding_layer(o)\n",
        "# rnn structure\n",
        "o = layers.GRU(128)(o)\n",
        "# output layer\n",
        "outputs = layers.Dense(num_labels, activation=\"softmax\")(o)\n",
        "\n",
        "# create model\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# compile the model\n",
        "model_1.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "hist_1 = model_1.fit(train_dataset, epochs=5, steps_per_epoch=int(0.2*len(train_dataset)),\n",
        "                     validation_data=validation_dataset, validation_steps=int(0.2*len(validation_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoSjo2v4O-zc",
        "outputId": "2a33c45d-c3b1-4ccf-d68b-ceaa4060a0c2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1125/1125 [==============================] - 49s 35ms/step - loss: 0.7419 - accuracy: 0.7043 - val_loss: 0.5913 - val_accuracy: 0.7659\n",
            "Epoch 2/5\n",
            "1125/1125 [==============================] - 36s 32ms/step - loss: 0.5628 - accuracy: 0.7900 - val_loss: 0.5171 - val_accuracy: 0.8006\n",
            "Epoch 3/5\n",
            "1125/1125 [==============================] - 35s 31ms/step - loss: 0.5414 - accuracy: 0.7971 - val_loss: 0.4793 - val_accuracy: 0.8153\n",
            "Epoch 4/5\n",
            "1125/1125 [==============================] - 37s 33ms/step - loss: 0.5000 - accuracy: 0.8153 - val_loss: 0.4753 - val_accuracy: 0.8188\n",
            "Epoch 5/5\n",
            "1125/1125 [==============================] - 37s 33ms/step - loss: 0.4911 - accuracy: 0.8167 - val_loss: 0.4801 - val_accuracy: 0.8214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict with model 1\n",
        "pred_1 = model_1.predict(validation_sentences)\n",
        "pred_1 = tf.argmax(pred_1, axis=1)\n",
        "# observe model 1's performance\n",
        "calculate_result(pred_1, validation_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvk7Hf-g0bFk",
        "outputId": "e67d2d37-df76-4dfa-9e3d-c9fdd779d356"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.01045942009797,\n",
              " 'f1': 0.822601777290057,\n",
              " 'precision': 0.830043764482926,\n",
              " 'recall': 0.8201045942009797}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create model_2 as LSTM\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "# vectorizing and embedding layers\n",
        "o = text_vectorization_layer(inputs)\n",
        "o = token_embedding_layer(o)\n",
        "# LSTM structure\n",
        "o = layers.LSTM(128)(o)\n",
        "# output layers\n",
        "outputs = layers.Dense(num_labels, activation=\"softmax\")(o)\n",
        "\n",
        "# create model\n",
        "model_2 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# compile the model\n",
        "model_2.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss=tf.keras.losses.categorical_crossentropy,\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "hist_2 = fit_model(model_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGY94Mm_1k5k",
        "outputId": "4fbdadfe-a7f3-463b-de5a-035392f1faab"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1125/1125 [==============================] - 46s 36ms/step - loss: 0.5489 - accuracy: 0.7992 - val_loss: 0.5557 - val_accuracy: 0.7940\n",
            "Epoch 2/5\n",
            "1125/1125 [==============================] - 45s 40ms/step - loss: 0.4548 - accuracy: 0.8379 - val_loss: 0.5065 - val_accuracy: 0.8151\n",
            "Epoch 3/5\n",
            "1125/1125 [==============================] - 39s 34ms/step - loss: 0.4346 - accuracy: 0.8444 - val_loss: 0.4937 - val_accuracy: 0.8146\n",
            "Epoch 4/5\n",
            "1125/1125 [==============================] - 38s 34ms/step - loss: 0.4008 - accuracy: 0.8581 - val_loss: 0.5039 - val_accuracy: 0.8153\n",
            "Epoch 5/5\n",
            "1125/1125 [==============================] - 38s 34ms/step - loss: 0.3956 - accuracy: 0.8583 - val_loss: 0.5148 - val_accuracy: 0.8188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the model\n",
        "pred_2 = model_2.predict(validation_sentences)\n",
        "pred_2 = tf.argmax(pred_2, axis=1)\n",
        "\n",
        "# observe model's performance\n",
        "calculate_result(pred_2, validation_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwW48WTq67vd",
        "outputId": "cf7e7ff8-a99c-4d5d-f5e9-eb4533533b0d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.55368727657884,\n",
              " 'f1': 0.8180663131658061,\n",
              " 'precision': 0.8243390851153358,\n",
              " 'recall': 0.8155368727657885}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create model 3 as hybrid character / sentence embeddings\n",
        "# setup sentence/token model\n",
        "sentence_inputs = layers.Input(shape=[], dtype=tf.string, name=\"sentence_input\") \n",
        "sentence_token = text_vectorization_layer(sentence_inputs)\n",
        "sentence_embedding = token_embedding_layer(sentence_token)\n",
        "sentence_gru = layers.GRU(128)(sentence_embedding)\n",
        "sentence_outputs = layers.Dense(num_labels, activation=\"tanh\", name=\"sentence_output\")(sentence_gru)\n",
        "sentence_model = tf.keras.Model(sentence_inputs, sentence_outputs)\n",
        "\n",
        "# setup character model\n",
        "character_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"character_input\")\n",
        "character_token = character_vectorization_layer(character_inputs)\n",
        "character_embedding = character_embedding_layer(character_token)\n",
        "character_gru = layers.GRU(128)(character_embedding)\n",
        "character_outputs = layers.Dense(num_labels, activation=\"tanh\", name=\"character_output\")(character_gru)\n",
        "character_model = tf.keras.Model(character_inputs, character_outputs)\n",
        "\n",
        "# concatenate outputs\n",
        "sentence_char_concat = layers.Concatenate(name=\"sentence_char_concat\")([sentence_model.output, character_model.output]) # has to be with model.outputs\n",
        "\n",
        "# create output layers and add dropouts for overfitting\n",
        "combined_dropout = layers.Dropout(0.5)(sentence_char_concat)\n",
        "combined_dense = layers.Dense(64, activation=\"tanh\")(combined_dropout)\n",
        "combined_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer_combined = layers.Dense(num_labels, activation=\"softmax\")(combined_dropout)\n",
        "\n",
        "# construct hybrid model\n",
        "model_4 = tf.keras.Model(inputs=[sentence_model.input, character_model.input], outputs=output_layer_combined)\n",
        "\n",
        "# compile the model\n",
        "model_4.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss=tf.keras.losses.categorical_crossentropy,\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "hist_4 = model_4.fit(train_dataset_hybrid, epochs=5, steps_per_epoch=int(0.2*len(train_dataset_hybrid)),\n",
        "                     validation_data=validation_dataset_hybrid, validation_steps=int(0.2*len(validation_dataset_hybrid)))\n"
      ],
      "metadata": {
        "id": "J1sAwx1a7mrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682974ad-b62d-4f4b-e5ba-9d26a28be6ad"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1125/1125 [==============================] - 139s 115ms/step - loss: 0.8382 - accuracy: 0.6677 - val_loss: 0.5730 - val_accuracy: 0.7725\n",
            "Epoch 2/5\n",
            "1125/1125 [==============================] - 128s 114ms/step - loss: 0.6758 - accuracy: 0.7304 - val_loss: 0.5385 - val_accuracy: 0.7994\n",
            "Epoch 3/5\n",
            "1125/1125 [==============================] - 117s 104ms/step - loss: 0.6367 - accuracy: 0.7462 - val_loss: 0.5381 - val_accuracy: 0.8067\n",
            "Epoch 4/5\n",
            "1125/1125 [==============================] - 131s 116ms/step - loss: 0.5976 - accuracy: 0.7606 - val_loss: 0.5483 - val_accuracy: 0.8099\n",
            "Epoch 5/5\n",
            "1125/1125 [==============================] - 129s 114ms/step - loss: 0.5811 - accuracy: 0.7716 - val_loss: 0.5781 - val_accuracy: 0.8052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the model\n",
        "pred_4 = model_4.predict(validation_dataset_hybrid)\n",
        "pred_4 = tf.argmax(pred_4, axis=1)\n",
        "\n",
        "# observe model's performance\n",
        "calculate_result(pred_4, validation_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBshkwm51bjN",
        "outputId": "ae5a52c6-b6c9-49fc-9c81-1c1ed2442800"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.21978021978022,\n",
              " 'f1': 0.8058392533750133,\n",
              " 'precision': 0.8159697421599741,\n",
              " 'recall': 0.8021978021978022}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create model 5 as hybrid sentence / index\n",
        "# setup sentence/token model\n",
        "sentence_inputs = layers.Input(shape=[], dtype=tf.string, name=\"sentence_input\") \n",
        "sentence_token = text_vectorization_layer(sentence_inputs)\n",
        "sentence_embedding = token_embedding_layer(sentence_token)\n",
        "sentence_gru = layers.GRU(128)(sentence_embedding)\n",
        "sentence_outputs = layers.Dense(num_labels, activation=\"tanh\", name=\"sentence_output\")(sentence_gru)\n",
        "sentence_model = tf.keras.Model(sentence_inputs, sentence_outputs)\n",
        "\n",
        "# setup index model\n",
        "index_inputs = layers.Input(shape=(18,), dtype=tf.int64, name=\"index_input\")\n",
        "index_hidden = layers.Dense(32, activation=\"tanh\")(index_inputs)\n",
        "index_outputs = layers.Dense(32, activation=\"softmax\", name=\"index_output\")(index_hidden)\n",
        "index_model = tf.keras.Model(index_inputs, index_outputs)\n",
        "\n",
        "# setup total model\n",
        "total_inputs = layers.Input(shape=(18,), dtype=tf.int64, name=\"total_input\")\n",
        "total_hidden = layers.Dense(32, activation=\"tanh\")(total_inputs)\n",
        "total_outputs = layers.Dense(32, activation=\"softmax\", name=\"total_output\")(total_hidden)\n",
        "total_model = tf.keras.Model(total_inputs, total_outputs)\n",
        "\n",
        "# combine total and index \n",
        "index_total_concat = layers.Concatenate(name=\"index_total_concat\")([index_model.output, total_model.output])\n",
        "\n",
        "# dropout to prevent overfitting\n",
        "d = layers.Dense(128, activation=\"tanh\")(index_total_concat)\n",
        "d = layers.Dropout(0.5)(d)\n",
        "\n",
        "# combine sentence and concated lines\n",
        "hybrid_layer = layers.Concatenate(name=\"index_total_sentence_concat\")([d, sentence_model.output])\n",
        "\n",
        "# create last hybrid output\n",
        "hybrid_output = layers.Dense(num_labels, activation=\"softmax\", name=\"index_total_sentence_output\")(hybrid_layer)\n",
        "\n",
        "# create model 5\n",
        "model_5 = tf.keras.Model(inputs=[index_model.input, total_model.input, sentence_model.input], outputs=hybrid_output, name=\"index_total_sentence_model\")\n",
        "\n",
        "# compile model \n",
        "model_5.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "hist_5 = model_5.fit(train_tribrid_dataset, epochs=5, steps_per_epoch=int(0.2*len(train_tribrid_dataset)),\n",
        "                     validation_data=validation_tribrid_dataset, validation_steps=int(0.2*len(validation_tribrid_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcblQo8S37e9",
        "outputId": "4985d144-cdc3-4966-c5ad-9b5e599555ef"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1125/1125 [==============================] - 49s 39ms/step - loss: 0.5584 - accuracy: 0.8038 - val_loss: 0.3486 - val_accuracy: 0.8752\n",
            "Epoch 2/5\n",
            "1125/1125 [==============================] - 56s 50ms/step - loss: 0.3311 - accuracy: 0.8767 - val_loss: 0.3265 - val_accuracy: 0.8813\n",
            "Epoch 3/5\n",
            "1125/1125 [==============================] - 44s 39ms/step - loss: 0.2898 - accuracy: 0.8982 - val_loss: 0.3180 - val_accuracy: 0.8849\n",
            "Epoch 4/5\n",
            "1125/1125 [==============================] - 45s 40ms/step - loss: 0.2452 - accuracy: 0.9186 - val_loss: 0.3196 - val_accuracy: 0.8835\n",
            "Epoch 5/5\n",
            "1125/1125 [==============================] - 44s 39ms/step - loss: 0.2297 - accuracy: 0.9224 - val_loss: 0.3466 - val_accuracy: 0.8734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add learning rate lowering callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=1, verbose=1, mode=\"min\")\n",
        "# add early stopping callback\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=0, mode=\"min\")\n",
        "# redo the model and add callback\n",
        "# setup sentence/token model\n",
        "sentence_inputs = layers.Input(shape=[], dtype=tf.string, name=\"sentence_input\") \n",
        "sentence_token = text_vectorization_layer(sentence_inputs)\n",
        "sentence_embedding = token_embedding_layer(sentence_token)\n",
        "sentence_gru = layers.GRU(128)(sentence_embedding)\n",
        "sentence_outputs = layers.Dense(num_labels, activation=\"tanh\", name=\"sentence_output\")(sentence_gru)\n",
        "sentence_model = tf.keras.Model(sentence_inputs, sentence_outputs)\n",
        "\n",
        "# setup index model\n",
        "index_inputs = layers.Input(shape=(18,), dtype=tf.int64, name=\"index_input\")\n",
        "index_hidden = layers.Dense(32, activation=\"tanh\")(index_inputs)\n",
        "index_outputs = layers.Dense(32, activation=\"softmax\", name=\"index_output\")(index_hidden)\n",
        "index_model = tf.keras.Model(index_inputs, index_outputs)\n",
        "\n",
        "# setup total model\n",
        "total_inputs = layers.Input(shape=(18,), dtype=tf.int64, name=\"total_input\")\n",
        "total_hidden = layers.Dense(32, activation=\"tanh\")(total_inputs)\n",
        "total_outputs = layers.Dense(32, activation=\"softmax\", name=\"total_output\")(total_hidden)\n",
        "total_model = tf.keras.Model(total_inputs, total_outputs)\n",
        "\n",
        "# combine total and index \n",
        "index_total_concat = layers.Concatenate(name=\"index_total_concat\")([index_model.output, total_model.output])\n",
        "\n",
        "# dropout to prevent overfitting\n",
        "d = layers.Dense(128, activation=\"tanh\")(index_total_concat)\n",
        "d = layers.Dropout(0.5)(d)\n",
        "\n",
        "# combine sentence and concated lines\n",
        "hybrid_layer = layers.Concatenate(name=\"index_total_sentence_concat\")([d, sentence_model.output])\n",
        "\n",
        "# create last hybrid output\n",
        "hybrid_output = layers.Dense(num_labels, activation=\"softmax\", name=\"index_total_sentence_output\")(hybrid_layer)\n",
        "\n",
        "# create model 5\n",
        "model_6 = tf.keras.Model(inputs=[index_model.input, total_model.input, sentence_model.input], outputs=hybrid_output, name=\"index_total_sentence_model\")\n",
        "\n",
        "# compile model \n",
        "model_6.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "hist_5 = model_6.fit(train_tribrid_dataset, epochs=25, steps_per_epoch=int(0.2*len(train_tribrid_dataset)),\n",
        "                     validation_data=validation_tribrid_dataset, validation_steps=int(0.2*len(validation_tribrid_dataset)),\n",
        "                     callbacks=[reduce_lr, early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H3i8MRGe_7Z",
        "outputId": "d48a6089-8a27-43ad-ccfc-2479f680d5ac"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1125/1125 [==============================] - 49s 40ms/step - loss: 0.5388 - accuracy: 0.8141 - val_loss: 0.3522 - val_accuracy: 0.8584 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "1125/1125 [==============================] - 45s 40ms/step - loss: 0.2999 - accuracy: 0.8896 - val_loss: 0.3259 - val_accuracy: 0.8851 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = model_1.predict([\"Participants ' perceptions of their quality of life and level of coercion were about the same.\"])\n",
        "r \n",
        "r\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5w1WlzIaVkp",
        "outputId": "70f4f83c-4e13-4bac-9cc2-05242961fc60"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.8406357e-04, 7.3077995e-03, 1.2037772e-01, 1.2795276e-04,\n",
              "        8.7190253e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}